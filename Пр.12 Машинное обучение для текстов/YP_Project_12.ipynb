{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект по классификации комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание проекта\n",
    "\n",
    "Требуется на основе набора данных с разметкой о токсичности правок обучить модель классифицировать комментарии пользователей интернет-магазина на позитивные и негативные для дальнейшей отправки на модерацию.\n",
    "\n",
    "### План выполнения проекта\n",
    "\n",
    "1. Загрузить и подготовить данные.\n",
    "2. Обучить разные модели и выбрать лучшую. \n",
    "3. Оформить выводы.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "- *text* - текст комментария\n",
    "- *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание\n",
    "1. [Подготовка](#1)\n",
    "2. [Обучение](#2)\n",
    "3. [Выводы](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка <a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "#грузим библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('stopwords')\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "# progress bar\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "\n",
    "# instantiate\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool, cv\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем датасет\n",
    "data_tox_comm = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_tox_comm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tox_comm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>143346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text\n",
       "toxic        \n",
       "0      143346\n",
       "1       16225"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tox_comm.groupby('toxic').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Смотрим дубликаты\n",
    "data_tox_comm.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wn.ADJ,\n",
    "                \"N\": wn.NOUN,\n",
    "                \"V\": wn.VERB,\n",
    "                \"R\": wn.ADV}\n",
    "    return tag_dict.get(tag, wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LemmMe(lemmatizer,text):\n",
    "    text_only_words = re.sub(r'[^a-zA-Z\\' ]', ' ', text)\n",
    "    text_list = nltk.word_tokenize(text_only_words)\n",
    "    lemms = [lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in text_list]\n",
    "    lemm_text = \" \".join(lemms).lower()\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#лемматизируем столбец text в датасете\n",
    "#закомментировано для экономии времени - результаты лемматизации сохранили в файл и берем сразу из него\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#data_tox_comm['lemm_text'] = data_tox_comm['text'].progress_apply(lambda x: LemmMe(lemmatizer,x))\n",
    "#data_tox_comm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запишем в файл, чтобы при следующих прогонах проекта брать сразу из файла\n",
    "#закомментировано, файл уже есть\n",
    "#data_tox_comm.to_csv('data_tox_comm_lemm.csv',index_label = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Считываем датасет с результатами лемматизации\n",
    "data_tox_comm_lemm = pd.read_csv('data_tox_comm_lemm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he match this background colour i 'm see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i 'm really not try to edit war it 's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d'aww he match this background colour i 'm see...  \n",
       "2  hey man i 'm really not try to edit war it 's ...  \n",
       "3  more i ca n't make any real suggestion on impr...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tox_comm_lemm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159571 entries, 0 to 159570\n",
      "Data columns (total 3 columns):\n",
      "text         159571 non-null object\n",
      "toxic        159571 non-null int64\n",
      "lemm_text    159565 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_tox_comm_lemm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4482</td>\n",
       "      <td>1993\\n\\n1994\\n\\n1995\\n\\n1996\\n\\n1997\\n\\n1998\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>193.61.111.53  15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17311</td>\n",
       "      <td>~ \\n\\n68.193.147.157</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52442</td>\n",
       "      <td>14:53,</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53787</td>\n",
       "      <td>92.24.199.233|92.24.199.233]]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61758</td>\n",
       "      <td>\"\\n\\n 199.209.144.211  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  toxic lemm_text\n",
       "4482   1993\\n\\n1994\\n\\n1995\\n\\n1996\\n\\n1997\\n\\n1998\\n...      0       NaN\n",
       "6300                                193.61.111.53  15:00      0       NaN\n",
       "17311                               ~ \\n\\n68.193.147.157      0       NaN\n",
       "52442                                             14:53,      0       NaN\n",
       "53787                      92.24.199.233|92.24.199.233]]      0       NaN\n",
       "61758                           \"\\n\\n 199.209.144.211  \"      0       NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#есть пропуски, смотрим\n",
    "data_tox_comm_lemm.query('lemm_text != lemm_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159565 entries, 0 to 159564\n",
      "Data columns (total 4 columns):\n",
      "index        159565 non-null int64\n",
      "text         159565 non-null object\n",
      "toxic        159565 non-null int64\n",
      "lemm_text    159565 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#удаляем пропуски\n",
    "data_tox_comm_lemm.dropna(inplace=True)\n",
    "data_tox_comm_lemm.reset_index(inplace=True)\n",
    "data_tox_comm_lemm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Возьмем выборку поменьше (5000 записей) для определения лучшей модели\n",
    "data_tox_comm_lemm_5000 = data_tox_comm_lemm.sample(5000).reset_index(drop=True)\n",
    "\n",
    "#разбиваем на признаки и целевой признак\n",
    "target_5000 = data_tox_comm_lemm_5000['toxic']\n",
    "features_5000 = data_tox_comm_lemm_5000['lemm_text']\n",
    "\n",
    "#корпус\n",
    "corpus_5000 = features_5000.values.astype('U')\n",
    "\n",
    "#стоп-слова\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#TF-IDF\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "count_tf_idf.fit(corpus_5000)\n",
    "tf_idf_5000 = count_tf_idf.transform(corpus_5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы по п.1.\n",
    "1. Загрузили датасет с англоязычными комментариями размером 159571 запись\n",
    "2. Лемматизировали записи с помощью Wordnet\n",
    "3. Для выбора лучшей модели решили взять не весь датасет, а выборку из 5000 записей\n",
    "4. Разбили выборку на признаки и целевой признак\n",
    "5. Создали из признаков корпус\n",
    "6. Создали матрицу cо значениями TF-IDF для корпуса с учетом стоп-слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение <a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_tox_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия\n",
      "F1 обучающей выборки= 0.23768663951910027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#логистическая регрессия\n",
    "model = LogisticRegression(random_state=12345,solver = 'sag', max_iter = 200)\n",
    "f1 = cross_val_score(model, tf_idf_5000, target_5000, scoring='f1', cv=3).mean()\n",
    "print('Логистическая регрессия')\n",
    "print('F1 обучающей выборки=',f1)\n",
    "print()\n",
    "#F1 обучающей выборки= 0.34099946882581794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoost\n",
    "#параметры\n",
    "cv_dataset = Pool(data=tf_idf_5000, \n",
    "                  label=target_5000, \n",
    "                  cat_features=None)\n",
    "\n",
    "params = {\"loss_function\": \"Logloss\",\n",
    "          \"custom_metric\": \"F1\",\n",
    "          \"verbose\": False,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем оптимальное количество итераций для CatBoost\n",
    "#закомментировано в целях экономии времени при последующих прогонах, ранее определена оптимальное iterations: 100\n",
    "#for best_it in range(20, 101, 20):\n",
    "#    params[\"iterations\"] = best_it\n",
    "#    scores = cv(cv_dataset,\n",
    "#                params,\n",
    "#                fold_count=3, \n",
    "#                plot=False)\n",
    "#    f1 = scores['test-F1-mean'].mean()    \n",
    "#    print('iterations:',best_it,'f1:',f1)\n",
    "\n",
    "#Результаты\n",
    "#iterations: 20 f1: 0.2900258781334798\n",
    "#iterations: 40 f1: 0.296753466292616\n",
    "#iterations: 60 f1: 0.3039233083872931\n",
    "#iterations: 80 f1: 0.32143640851624783\n",
    "#iterations: 100 f1: 0.33954999731528096\n",
    "        \n",
    "params[\"iterations\"] = 100 #f1 = 0.339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM\n",
    "d_train_5000 = lgb.Dataset(tf_idf_5000, label=target_5000)\n",
    "params_lgb = {'metrics':None} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция расчета F1, поскольку у LightGBM нет такой метрики\n",
    "def lgb_f1_score(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "    y_pred = np.abs(np.round(preds))\n",
    "    y_pred[y_pred > 1] = 1\n",
    "    return 'f1', f1_score(y_true, y_pred,average='binary'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подбираем оптимальное количество итераций для LightGBM\n",
    "##закомментировано в целях экономии времени при последующих прогонах, ранее определено num_iterations = 30\n",
    "#warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#for best_iterations in range(10, 251, 20):\n",
    "#    params_lgb['num_iterations'] = best_iterations\n",
    "#    f1 = lgb.cv(params=params_lgb,\n",
    "#                    train_set=d_train_5000,\n",
    "#                    nfold=3,\n",
    "#                    feval=lgb_f1_score)\n",
    "#    print('num_iterations:',best_iterations,'f1:',np.mean(f1['f1-mean']))\n",
    "\n",
    "#Результаты\n",
    "#num_iterations: 10 f1: 0.182654539432826\n",
    "#num_iterations: 30 f1: 0.37166400123305\n",
    "#num_iterations: 50 f1: 0.4351030334048784\n",
    "#num_iterations: 70 f1: 0.46569111005462926\n",
    "#num_iterations: 90 f1: 0.48306930893816347\n",
    "#num_iterations: 110 f1: 0.49437324776546593\n",
    "#num_iterations: 130 f1: 0.5028250945434569\n",
    "#num_iterations: 150 f1: 0.5096944593258662\n",
    "#num_iterations: 170 f1: 0.5150065753023975\n",
    "#num_iterations: 190 f1: 0.5195074529179533\n",
    "#num_iterations: 210 f1: 0.5233638928328848\n",
    "#num_iterations: 230 f1: 0.5266983585393978\n",
    "#num_iterations: 250 f1: 0.5295467694404704\n",
    "\n",
    "params_lgb['num_iterations'] = 250 #f1 = 0.529\n",
    "warnings.simplefilter(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выбираем лучшей моделью LightGBM\n",
    "#Работаем уже с полной выборкой - обучаем на трейне и проверяем на тесте\n",
    "#P.S С полным датасетом работать не получается - падает ядро на шаге создания TF-DF, \n",
    "#пришлось сократить датасет до 100000 записей и работать дальше уже с сокращенной версией\n",
    "data_tox_comm_lemm_ = data_tox_comm_lemm.sample(100000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем на признаки и целевой признак\n",
    "target = data_tox_comm_lemm_['toxic']\n",
    "features = data_tox_comm_lemm_['lemm_text']\n",
    "\n",
    "#разбиваем на обучающую и тестовую выборки\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#корпус обучающей выборки\n",
    "corpus_train = features_train.values.astype('U')\n",
    "\n",
    "#корпус тестовой выборки\n",
    "corpus_test = features_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del target, features,data_tox_comm_lemm,d_train_5000,cv_dataset,model,count_tf_idf,data_tox_comm_lemm_5000,target_5000,features_5000,corpus_5000,tf_idf_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF \n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучаем на train\n",
    "count_tf_idf.fit(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем TF-IDF для train\n",
    "tf_idf_train = count_tf_idf.transform(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем TF-IDF для test\n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 101397)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 101397)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus_train,corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 55s, sys: 869 ms, total: 4min 56s\n",
      "Wall time: 4min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_iterations=250, num_leaves=31,\n",
       "               objective='binary', random_state=None, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Обучаем модель LightGBM\n",
    "clf = lgb.LGBMClassifier(objective='binary',num_iterations=250)\n",
    "clf.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "F1 тестовой выборки = 0.7647317502198768\n",
      "\n",
      "CPU times: user 7.4 s, sys: 1.34 ms, total: 7.4 s\n",
      "Wall time: 7.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Предсказываем и замеряем (LightGBM)\n",
    "pred_test = clf.predict(tf_idf_test)\n",
    "f1 = f1_score(target_test, pred_test)\n",
    "print('LightGBM')\n",
    "print(\"F1 тестовой выборки =\", f1)\n",
    "print()\n",
    "\n",
    "#F1 тестовой выборки = 0.764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 константной модели: 0.18735498839907194\n"
     ]
    }
   ],
   "source": [
    "#Проверка на адекватность\n",
    "#константная модель для проверки адекватности - все 1\n",
    "pred_const = np.ones(target_test.shape)\n",
    "print(\"F1 константной модели:\", f1_score(target_test, pred_const))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22191   225]\n",
      " [  845  1739]]\n"
     ]
    }
   ],
   "source": [
    "#матрица ошибок\n",
    "print(confusion_matrix(target_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#использовать BERT (а именно код из последнего урока) в проекте не удалось, поскольку ядро при работе кода BERT постоянно падает \n",
    "#(да и вообще падает при каждом удобном случае)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы по п.2\n",
    "1. Используя выборку в 5000 записей, сравнили c помощью кросс-валидации три модели: логистическую регресию, CatBoost, LightGBM. \n",
    "2. Выбрали лучшую - LightGBM, у нее F1 лучше прочих (0.529) и она быстрее того же CatBoost.\n",
    "3. Разбили полный датасет размером 159565 записей на учебный и тестовый (25%)\n",
    "3. Обучили выбранную модель на учебном датасете\n",
    "4. Получили предсказания на тесте.\n",
    "5. Метрика модели на тесте F1 = 0.764, что соответствует требованию проекта (F1 не меньше 0.75)\n",
    "6. Проверили модель на адекватность, сравнив с константной моделью с предсказаниями-единицами. F1 константной модели = 0.18, наша модель более чем адекватна.\n",
    "6. Построили матрицу ошибок. Судя по ней, модель пропускает треть токсичных комментариев, оценивая их как нетоксичные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Общие выводы<a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Открыли и лемматизировали датасет с комментариями и оценкой их токсичности размером 159 571 записей\n",
    "2. На выборке из 5000 записей обучили разные модели и выбрали лучшую - LightGBM\n",
    "3. Выбранную модель обучили на учебной части полного датасета и проверили на тесте. \n",
    "4. Получили значение F1 для теста, равное 0.764, что соответствует требованиям проекта (>=0.75).\n",
    "5. Подтвердили адекватность модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
